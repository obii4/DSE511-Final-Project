{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b434de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b8351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial data load and num of rows and cols\n",
    "data = pd.read_csv('~/Desktop/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b94c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mbti_text(data):\n",
    "    label = data['type']\n",
    "\n",
    "    personalities_list = ['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP',\n",
    "                          'INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP']\n",
    "    personalities_list = [p.lower() for p in personalities_list]\n",
    "    \n",
    "    #remove links\n",
    "    data['posts'] = data['posts'].apply(lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]', '', x.replace(\"|\",\" \") + \" \")) #links\n",
    "    \n",
    "    #remove MBTI personality labels from data['posts']\n",
    "    for i in range(len(personalities_list)-1):\n",
    "        data['posts'] = data['posts'].str.replace(personalities_list[i], '')\n",
    "    \n",
    "    #lowercase\n",
    "    data['posts'] = data['posts'].apply(lambda x: x.lower()) \n",
    "    \n",
    "    #remove nonwords\n",
    "    data['posts'] = data['posts'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','',x))\n",
    "    \n",
    "    #remove puncuation\n",
    "    data['posts'] = data['posts'].apply(lambda x: re.sub(r'[\\.+]', \".\",x)) \n",
    "    \n",
    "    #remove extra spaces\n",
    "    data['posts'] = data['posts'].str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ') \n",
    "    \n",
    "    clean = data\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7516e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/6qzh7bb57y7g_z7dxyz4hsy00000gn/T/ipykernel_36077/769568157.py:25: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['posts'] = data['posts'].str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "clean_text = clean_mbti_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13dc0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(text):\n",
    "    extroversion = text[text['type'].isin(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP'])]\n",
    "    extroversion = extroversion.replace(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP'], \n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    introversion = text[text['type'].isin(['INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP'])]\n",
    "    introversion = introversion.replace(['INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP'], \n",
    "                                    [1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "    intuition = text[text['type'].isin(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'INFJ', 'INFP', 'INTJ', 'INTP'])]\n",
    "    intuition = intuition.replace(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'INFJ', 'INFP', 'INTJ', 'INTP'], \n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    sensing = text[text['type'].isin(['ISFJ', 'ISFP', 'ISTJ', 'ISTP','ESFJ', 'ESFP', 'ESTJ', 'ESTP'])]\n",
    "    sensing = sensing.replace(['ISFJ', 'ISFP', 'ISTJ', 'ISTP','ESFJ', 'ESFP', 'ESTJ', 'ESTP'], \n",
    "                                    [1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "    thinking = text[text['type'].isin(['ENTJ', 'ENTP','ESTJ', 'ESTP','INTJ', 'INTP', 'ISTJ', 'ISTP'])]\n",
    "    thinking = thinking.replace(['ENTJ', 'ENTP','ESTJ', 'ESTP','INTJ', 'INTP', 'ISTJ', 'ISTP'], \n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    feeling = text[text['type'].isin(['ENFJ', 'ENFP','ESFJ', 'ESFP', 'INFJ', 'INFP', 'ISFJ', 'ISFP'])]\n",
    "    feeling = feeling.replace(['ENFJ', 'ENFP','ESFJ', 'ESFP', 'INFJ', 'INFP', 'ISFJ', 'ISFP'], \n",
    "                                    [1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "    judging = text[text['type'].isin(['ENFJ','ENTJ', 'ESFJ', 'ESTJ', 'INFJ', 'INTJ', 'ISFJ', 'ISTJ'])]\n",
    "    judging = judging.replace(['ENFJ','ENTJ', 'ESFJ', 'ESTJ', 'INFJ', 'INTJ', 'ISFJ', 'ISTJ'], \n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    percieving = text[text['type'].isin(['ENFP', 'ENTP', 'ESFP', 'ESTP', 'INFP', 'INTP', 'ISFP', 'ISTP'])]\n",
    "    percieving = percieving.replace(['ENFP', 'ENTP', 'ESFP', 'ESTP', 'INFP', 'INTP', 'ISFP', 'ISTP'], \n",
    "                                    [1, 1, 1, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    EI = pd.concat([extroversion, introversion])\n",
    "    NS = pd.concat([intuition, sensing])\n",
    "    TF = pd.concat([thinking, feeling])\n",
    "    JP = pd.concat([judging, percieving])\n",
    "    \n",
    "    return EI, NS, TF, JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf79e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "EI, NS, TF, JP = text_split(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c57b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_x = EI['posts']\n",
    "EI_y = EI['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368f75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process raw text into ML compatible features\n",
    "vectorizer = TfidfVectorizer(min_df=3, \n",
    "             stop_words='english',ngram_range=(1, 2), lowercase=True)  \n",
    "vectorizer.fit(EI_x)\n",
    "\n",
    "X = vectorizer.transform(EI_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e0e16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, EI_y, \n",
    "                                   test_size=0.15, shuffle=True, stratify=EI_y, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                 test_size=0.15/0.85, shuffle=True, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a4f0a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.        , 52.72727273, 55.45454545, 58.18181818, 60.90909091,\n",
       "       63.63636364, 66.36363636, 69.09090909, 71.81818182, 74.54545455,\n",
       "       77.27272727, 80.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(50,80, num = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9effc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.791079 using {'C': 80.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 50.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 50.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 50.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.788780 (0.006173) with: {'C': 50.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 50.0, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 52.72727273, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 52.72727273, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 52.72727273, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.788780 (0.006173) with: {'C': 52.72727273, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 52.72727273, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 55.45454545, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 55.45454545, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 55.45454545, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.788780 (0.006173) with: {'C': 55.45454545, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 55.45454545, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 58.18181818, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 58.18181818, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 58.18181818, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.788780 (0.006173) with: {'C': 58.18181818, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 58.18181818, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 60.90909091, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 60.90909091, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 60.90909091, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.788780 (0.006173) with: {'C': 60.90909091, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 60.90909091, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 63.63636364, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 63.63636364, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 63.63636364, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.789546 (0.006861) with: {'C': 63.63636364, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 63.63636364, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 66.36363636, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 66.36363636, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 66.36363636, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.789546 (0.006861) with: {'C': 66.36363636, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 66.36363636, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 69.09090909, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 69.09090909, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 69.09090909, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.789546 (0.006861) with: {'C': 69.09090909, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 69.09090909, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 71.81818182, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 71.81818182, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 71.81818182, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.789546 (0.006861) with: {'C': 71.81818182, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 71.81818182, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 74.54545455, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 74.54545455, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 74.54545455, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.790312 (0.007408) with: {'C': 74.54545455, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 74.54545455, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 77.27272727, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 77.27272727, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 77.27272727, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.790312 (0.007408) with: {'C': 77.27272727, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 77.27272727, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.788780 (0.006173) with: {'C': 80.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788780 (0.006173) with: {'C': 80.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788780 (0.006173) with: {'C': 80.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.791079 (0.008208) with: {'C': 80.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.788780 (0.006173) with: {'C': 80.0, 'penalty': 'l2', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=1000)\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'saga', 'sag']\n",
    "penalty = ['l2']\n",
    "c_values = [50.        , 52.72727273, 55.45454545, 58.18181818, 60.90909091,\n",
    "       63.63636364, 66.36363636, 69.09090909, 71.81818182, 74.54545455,\n",
    "       77.27272727, 80.        ]\n",
    "\n",
    "#define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_val,y_val)\n",
    "\n",
    "#summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b34c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(random_state=0, C=63, penalty='l2', solver = 'newton-cg', max_iter=1000) \n",
    "\n",
    "t0 = time.time()\n",
    "lg.fit(X_train,y_train)\n",
    "t1 = time.time() # ending time\n",
    "lg_train_time = t1-t0\n",
    "\n",
    "t0 = time.time()\n",
    "y_true, y_pred_lg = y_test, lg.predict(X_test)\n",
    "t1 = time.time() # ending time\n",
    "lg_pred_time = t1-t0\n",
    "\n",
    "lg_report = classification_report(y_true, y_pred_lg, output_dict=True)\n",
    "df_lg = pd.DataFrame(lg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "024fe2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820359</td>\n",
       "      <td>0.856388</td>\n",
       "      <td>0.851767</td>\n",
       "      <td>0.838373</td>\n",
       "      <td>0.848086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.970060</td>\n",
       "      <td>0.851767</td>\n",
       "      <td>0.713363</td>\n",
       "      <td>0.851767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.586724</td>\n",
       "      <td>0.909686</td>\n",
       "      <td>0.851767</td>\n",
       "      <td>0.748205</td>\n",
       "      <td>0.835271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>0.851767</td>\n",
       "      <td>1302.000000</td>\n",
       "      <td>1302.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0            1  accuracy    macro avg  weighted avg\n",
       "precision    0.820359     0.856388  0.851767     0.838373      0.848086\n",
       "recall       0.456667     0.970060  0.851767     0.713363      0.851767\n",
       "f1-score     0.586724     0.909686  0.851767     0.748205      0.835271\n",
       "support    300.000000  1002.000000  0.851767  1302.000000   1302.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5890717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
